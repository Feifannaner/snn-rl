{
 "metadata": {
  "name": "",
  "signature": "sha256:3085d22305d331e622ab2f276b94199607593351bd337f1c9be935f12531d3fc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now reopen the file \"simulation.hdf5\" and try to plot all the important parameters to try to understand what the network is doing\n",
      "\n",
      "firstly lets, import all required libs"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will firstly plot the neuron voltage. we will get the first 10000 points and look for the max value there, then we will take the next 10000 points and look for the minum, and keep till the end. that way we convert 1,200,000 in 112 which are displayed bellow. You can choose for different \"compresion\" rates (10,100,1000,10000). If you choose 1 you will be seeing the real data. But remember, when more points are shown more ram is use."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from brianPlotter import *\n",
      "bp = brianPlotter('simulation.hdf5',permision = \"r\")\n",
      "\n",
      "start = 119 #seconds\n",
      "end = 120\n",
      "bp.plotLine('voltage',start,end)\n",
      "bp.plotLine('excitatory',start,end)\n",
      "bp.plotLine('inhibitory',start,end)\n",
      "bp.plotScatter(start,end) #downsampling not yet implemented for scatter\n",
      "\n",
      "del bp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We can indentify some tendency among all neurons, we will now plot the weights to see if there is a correlation between this behaviour and the weights.\n",
      "\n",
      "Firstly , we will plot excitatory weights which corresponds to the synapses that connects the first layer and the second on.\n",
      "Secondly, we plot the inhibitory weights which represents the connection within neurons of the second layer, a neuron can inhibit itself in out model, so there are no weights for the diagonal."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "it's interesting to notice that row 4 and 10, of the excitatory weigths remain constant, that's because then neuron 4 and 10 of the first layer never fired, because the all character have those pixels off.\n"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}