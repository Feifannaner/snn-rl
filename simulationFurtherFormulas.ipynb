{
 "metadata": {
  "name": "",
  "signature": "sha256:e4b2c9b53f835a46dbc0ba92b528260cb6c427c2945d0f97332bbd6e292526dc"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from brian import *\n",
      "\n",
      "class dictionary():\n",
      "\tdef spikeTimes(self, dictionaryLongitude, spikeInterval, spikesPerChar, epochs):\n",
      "\n",
      "\t\tdictionary = zeros(26, dtype='c1, (5,3)u1')\n",
      "\t\tdictionary[:] =[('A',[[1, 0, 1],[0, 1, 0],[0, 0, 0],[0, 1, 0],[0, 1, 0]]),\n",
      "\t\t\t\t\t    ('B',[[0, 0, 1],[0, 1, 0],[0, 0, 1],[0, 1, 0],[0, 0, 1]]),\n",
      "\t\t\t\t\t    ('C',[[0, 0, 0],[0, 1, 1],[0, 1, 1],[0, 1, 1],[0, 0, 0]]),\n",
      "\t\t\t\t\t    ('D',[[0, 0, 1],[0, 1, 0],[0, 1, 0],[0, 1, 0],[0, 0, 1]]),\n",
      "\t\t\t\t\t    ('E',[[0, 0, 0],[0, 1, 1],[0, 0, 1],[0, 1, 1],[0, 0, 0]]),\n",
      "\t\t\t\t\t    ('F',[[0, 0, 0],[0, 1, 1],[0, 0, 1],[0, 1, 1],[0, 1, 1]]),\n",
      "\t\t\t\t\t    ('G',[[0, 0, 0],[0, 1, 1],[0, 1, 1],[0, 1, 0],[0, 0, 0]]),\n",
      "                        ('H',[[0, 1, 0],[0, 1, 0],[0, 0, 0],[0, 1, 0],[0, 1, 0]]),\n",
      "                        ('I',[[0, 0, 0],[1, 0, 1],[1, 0, 1],[1, 0, 1],[0, 0, 0]]),\n",
      "\t\t\t\t\t    ('J',[[0, 0, 0],[1, 1, 0],[1, 1, 0],[0, 1, 0],[0, 0, 0]]),\n",
      "\t\t\t\t\t    ('K',[[0, 1, 0],[0, 0, 1],[0, 1, 1],[0, 0, 1],[0, 1, 0]]),\n",
      "\t\t\t\t\t    ('L',[[0, 1, 1],[0, 1, 1],[0, 1, 1],[0, 1, 1],[0, 0, 0]]),\n",
      "\t\t\t\t\t    ('M',[[0, 1, 0],[0, 0, 0],[0, 1, 0],[0, 1, 0],[0, 1, 0]]),\n",
      "\t\t\t\t\t    ('N',[[0, 1, 0],[0, 0, 0],[0, 0, 0],[0, 0, 0],[0, 1, 0]]),\n",
      "\t\t\t\t\t    ('O',[[1, 0, 1],[0, 1, 0],[0, 1, 0],[0, 1, 0],[1, 0, 1]]),\n",
      "\t\t\t\t\t    ('P',[[0, 0, 0],[0, 1, 0],[0, 0, 0],[0, 1, 1],[0, 1, 1]]),\n",
      "\t\t\t\t\t    ('Q',[[1, 0, 1],[0, 1, 0],[0, 1, 0],[1, 0, 1],[1, 1, 0]]),\n",
      "\t\t\t\t\t    ('R',[[0, 0, 1],[0, 1, 0],[0, 0, 0],[0, 0, 1],[0, 1, 0]]),\n",
      "\t\t\t\t\t    ('S',[[1, 0, 0],[0, 1, 1],[1, 0, 1],[1, 1, 0],[0, 0, 1]]),\n",
      "\t\t\t\t\t    ('T',[[0, 0, 0],[1, 0, 1],[1, 0, 1],[1, 0, 1],[1, 0, 1]]),\n",
      "\t\t\t\t\t    ('U',[[0, 1, 0],[0, 1, 0],[0, 1, 0],[0, 1, 0],[0, 0, 0]]),\n",
      "\t\t\t\t\t    ('V',[[0, 1, 0],[0, 1, 0],[0, 1, 0],[0, 1, 0],[1, 0, 1]]),\n",
      "\t\t\t\t\t    ('W',[[0, 1, 0],[0, 1, 0],[0, 1, 0],[0, 0, 0],[0, 1, 0]]),\n",
      "\t\t\t\t\t    ('X',[[0, 1, 0],[0, 1, 0],[1, 0, 1],[0, 1, 0],[0, 1, 0]]),\n",
      "\t\t\t\t\t    ('Y',[[0, 1, 0],[0, 1, 0],[1, 0, 1],[1, 0, 1],[1, 0, 1]]),\n",
      "\t\t\t\t\t    ('Z',[[0, 0, 0],[1, 1, 0],[1, 0, 1],[0, 1, 1],[0, 0, 0]])]\n",
      "\t\t\n",
      "\t\tself.dictionary = dictionary\n",
      "\n",
      "\t\tspikeArray = array([]).reshape(0,2)\n",
      "\n",
      "\t\ttime = 0 * ms\n",
      "        \n",
      "\t\tfor indexEpoch in range (0, epochs):\n",
      "\t\t\tfor indexDictionary in range(0,dictionaryLongitude):\n",
      "\t\t\t\t\n",
      "\t\t\t\tvector = dictionary[indexDictionary][1].reshape([1,15])\n",
      "\t\t\t\tfor charSpikeIndex in range(0,spikesPerChar):\n",
      "\n",
      "\t\t\t\t\ttime = time + spikeInterval\n",
      "\t\t\t\t\tfor indexPixel in range(0,15):  \n",
      "                        \n",
      "\t\t\t\t\t\tif vector[0][indexPixel] == 0:\n",
      "\t\t\t\t\t\t\tspike = array([indexPixel, time])\n",
      "\t\t\t\t\t\t\tspikeArray = vstack([spikeArray,spike])\n",
      "\n",
      "\t\treturn spikeArray "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "C:\\Users\\Nate_2\\Anaconda\\lib\\site-packages\\brian\\utils\\sparse_patch\\__init__.py:39: UserWarning: Couldn't find matching sparse matrix patch for scipy version 0.14.0, but in most cases this shouldn't be a problem.\n",
        "  warnings.warn(\"Couldn't find matching sparse matrix patch for scipy version %s, but in most cases this shouldn't be a problem.\" % scipy.__version__)\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "epochs = 5 \n",
      "spikeMiliseconds = 100\n",
      "spikeInterval = spikeMiliseconds * ms\n",
      "spikeIntervalUnformatted = spikeMiliseconds * .001\n",
      "dictionaryLongitude = 4\n",
      "spikesPerChar=3\n",
      "firstLayerSize = 15\n",
      "totalTime = epochs * spikesPerChar * dictionaryLongitude * spikeInterval \n",
      "\n",
      "taum = 20 * ms\n",
      "taue = 1 * ms\n",
      "taui = 10 * ms\n",
      "Vt = 5 * mV\n",
      "Vr = 0 * mV\n",
      "\n",
      "Rm = 80\n",
      "## added tauS constant below ##\n",
      "tauS = 2\n",
      "tauMax = 30\n",
      "tauMin = 2\n",
      "#tauM = 30 * ms # appears different than taum above due to the article specifying this as 30\n",
      "tauM = 30 # removed ms for compatibility\n",
      "\n",
      "SimulationDuration = 10000\n",
      "epochMsDuration = (SimulationDuration / epochs) * 10 # Times 10 is to adjust to Ms scale\n",
      "\n",
      "numberOfPixels = 15\n",
      "#neuronFiringThreshold = 10 * mV\n",
      "neuronFiringThreshold = 10 # removed mV for compatibility\n",
      "W = np.random.uniform(0.5,1.0,[15,4]) # Initial weights\n",
      "# none to 1 below\n",
      "numberOfNeurons = 4\n",
      "R = [[1] * dictionaryLongitude for i in range(numberOfPixels)] # Initial Resistance Values\n",
      "## Added 1 init below but I don't really know what the right init value is\n",
      "Iden = [[1] * dictionaryLongitude for i in range(numberOfPixels)] # Initial Dendritic Post Synaptic Current\n",
      "## Added 1 init below but I don't really know what the right init value is\n",
      "tauD = [[1] * dictionaryLongitude for i in range(numberOfPixels)] # Initial tauD\n",
      "tF = [[None] * dictionaryLongitude for i in range(numberOfPixels)] # Initial pre-synaptic spike times\n",
      "\n",
      "Is = [1] * dictionaryLongitude\n",
      "Um = [1] * dictionaryLongitude\n",
      "\n",
      "Ureset = -.001\n",
      "\n",
      "Mv = []\n",
      "\n",
      "dictionary = dictionary()\n",
      "spiketimes = dictionary.spikeTimes(dictionaryLongitude, spikeInterval, spikesPerChar, epochs)\n",
      "LIK = SpikeGeneratorGroup(firstLayerSize, spiketimes)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "from sympy import * # used for differentiation\n",
      "import math # used for natural log\n",
      "\n",
      "class gupta_paper:\n",
      "\n",
      "\tneuronIndex = 0\n",
      "\tneuronCounter = -1\n",
      "\tt = 1\n",
      "\tMv = []\n",
      "\tdef run_model(self):\n",
      "\t\t\n",
      "\t\t#dictionary = self.dictionary\n",
      "\t\t#spiketimes = self.spiketimes\n",
      "\n",
      "\t\teqs = Equations('''\n",
      "\t\t      V : volt\n",
      "\t\t\t  ''')\n",
      "\n",
      "\t\tADDS = NeuronGroup(N=4, model=eqs,threshold=Vt, reset=Vr)\n",
      "\n",
      "\t\tdef returnUm(self):\n",
      "\t\t\tneuronIndex = self.neuronIndex\n",
      "\t\t\tt = self.t\n",
      "\t\t\t\n",
      "\t\t\t# Weight loop\n",
      "\t\t\tfor WIndex in range(len(W)):\n",
      "\t\t\t\tif abs(W[WIndex][neuronIndex]) <= 1:\n",
      "\t\t\t\t\ttauD[WIndex][neuronIndex] = tauMax - abs(W[WIndex][neuronIndex])*(tauMax-tauMin)\n",
      "\n",
      "\t\t\t#Resistance loop\n",
      "\t\t\tfor RIndex in range(len(R)):\n",
      "\t\t\t\tR[RIndex][neuronIndex] = ((tauD[RIndex][neuronIndex]*neuronFiringThreshold) / Rm) * ((tauM / tauD[RIndex][neuronIndex]) ** (tauM / tauM - tauD[RIndex][neuronIndex]))\n",
      "\n",
      "\t\t\t#Dedritic total post-synaptic current\n",
      "\t\t\t# Solving for Id in the formula in the article yeilded the below equation\n",
      "\t\t\t# -Id**2/(2*Td) + Id*Rd*W/Tfd\n",
      "\t\t\t# That is implemented below\n",
      "\t\t\te = math.e\n",
      "\t\t\t\n",
      "\t\t\tfor IdIndex in range(len(Iden)):\n",
      "\t\t\t\ttauDen = tauD[IdIndex][neuronIndex]\n",
      "\t\t\t\tr = R[IdIndex][neuronIndex]\n",
      "\t\t\t\tw = W[IdIndex][neuronIndex]\n",
      "\t\t\t\ttPreSyn = spiketimes[IdIndex + (neuronIndex * len(Iden))][0]\n",
      "\t\t\t\tId2 = Iden[IdIndex][neuronIndex]\n",
      "\t\t\t\tDt = t - tPreSyn\n",
      "\t\t\t\tDiracFun = 1/Dt\n",
      "\n",
      "\t\t\t\t# dirac test\n",
      "\t\t\t\t# t in dirac forumula means curent time or last spike time?\n",
      "\t\t\t\tif (t > -(Dt/2) and t < (Dt/2)):\n",
      "\t\t\t\t\tIden[IdIndex][neuronIndex] = ((-Id2**2)/(2*tauDen))+((Id2*r*w)*DiracFun)\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tDiracFun = 0\n",
      "\t\t\t\t\tIden[IdIndex][neuronIndex] = ((-Id2**2)/(2*tauDen))+((Id2*r*w)*DiracFun)\n",
      "\n",
      "\t\t\t### Synapse directly to soma ###\n",
      "\t\t\t# Solving for Id in the formula in the article yeilded the below equation\n",
      "\t\t\t# -Is_1**2/(2*Ts_1) + (Is_1*DiracWeightedSum)/Ts_1\n",
      "\t\t\t# That is implemented below\n",
      "\t\t\t# To calculate the DiracWeightedSum the spike times with the dirac function applied are multipled by the synapse weight \n",
      "\t\t\t# and summed then divided by the number of synapses for the neuron \n",
      "\t\t\tDiracWeightedSum = 0\n",
      "\t\t\tfor DiracIndex in range(len(Is)):\n",
      "\t\t\t\ttPreSyn = spiketimes[DiracIndex + (neuronIndex * len(Is))][0]\n",
      "\t\t\t\tDt = t - tPreSyn\n",
      "\t\t\t\tDiracFun = 1/Dt\n",
      "\t\t\t\t# dirac test  # TODO: not sure dirac is implemented correctly here\n",
      "\t\t\t\tif (t > -(Dt/2) and t < (Dt/2)):\n",
      "\t\t\t\t\tDiracFunctionWithSpikeTimes = DiracFun # (-t+tPreSyn)/tauDen\n",
      "\t\t\t\telse:\n",
      "\t\t\t\t\tDiracFunctionWithSpikeTimes = 0\n",
      "\t\t\t\tDiracWeightedSum = DiracWeightedSum + W[WIndex][neuronIndex] * DiracFunctionWithSpikeTimes\n",
      "\t\t\tDiracWeightedSum = DiracWeightedSum / len(Iden)\n",
      "\n",
      "\t\t\tIs2 = Is[neuronIndex]\n",
      "\n",
      "\t\t\tIs[neuronIndex] = (-Is2**2)/(2*tauS) + ((Is2*DiracWeightedSum)/tauS)\n",
      "\n",
      "\t\t\t### Soma membrane potential ###\n",
      "\t\t\t# Solving for Um in the formula in the article yeilded the below equation\n",
      "\t\t\t## -Um**2/(2*Tm) + Um*(Rm*SummedDendriteGroupX + Rm*SynapseToSomaX)/Tm\n",
      "\t\t\t# That is implemented below\n",
      "\t\t\tUm2 = Um[neuronIndex]\n",
      "\t\t\tSummedDendriteGroup = sum(Iden[ 0:len(Iden) ][neuronIndex])\n",
      "\t\t\tSynapseToSoma = Is[neuronIndex]\n",
      "\n",
      "\t\t\tUm[neuronIndex] = -Um2**2/(2*tauM) + Um2*(Rm*SummedDendriteGroup + Rm*SynapseToSoma)/tauM\n",
      "\n",
      "\t\t\tif Um[neuronIndex] == 0: Um[neuronIndex] = Ureset\n",
      "\n",
      "\t\t\t### After all neurons are cycled through the time is iterated by one\n",
      "\t\t\tneuronIndex = neuronIndex + 1\n",
      "\t\t\tif neuronIndex == 4: \n",
      "\t\t\t\tneuronIndex = 0\n",
      "\t\t\t\tt = t + 1\n",
      "\t\t\tself.neuronIndex = neuronIndex\n",
      "\t\t\tself.t = t\n",
      "\n",
      "\t\t\treturn Um[neuronIndex] * mV;\t\n",
      "\n",
      "\t\t# This network_operation runs the membrane potential calculation function for every milisecond that occurs.\n",
      "\t\t# The Um output is saved directly to the ADDS V (voltage) records for use with Brian's code.\n",
      "\t\t@network_operation\n",
      "\t\tdef myoperation():\n",
      "\t\t\tself.neuronCounter = self.neuronCounter + 1\n",
      "\t\t\tif self.neuronCounter == 4:\n",
      "\t\t\t\tself.neuronCounter = 0\n",
      "\n",
      "\t\t\tADDS[self.neuronCounter][0].V = returnUm(self)\n",
      "\n",
      "\t\tM = SpikeMonitor(ADDS)\n",
      "\t\tMv = StateMonitor(ADDS, 'V', record=True)\n",
      "\n",
      "\t\ttotalRunTime = 500\n",
      "\n",
      "\t\trun(totalRunTime*ms,threads=2, report='text')\n",
      "        \n",
      "\t\tself.Mv = Mv\n",
      "\n",
      "\tdef __init__(self):\n",
      "\t\tself.run_model()\n",
      "\n",
      "def main():\n",
      "\trun_gupta_paper = gupta_paper()\n",
      "\n",
      "if  __name__ =='__main__':main()\n",
      "    \n",
      "Mv = gupta_paper.Mv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "10% complete, 10s elapsed, approximately 1m 23s remaining.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "23% complete, 20s elapsed, approximately 1m 4s remaining.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "36% complete, 30s elapsed, approximately 52s remaining.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "48% complete, 40s elapsed, approximately 42s remaining.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "61% complete, 50s elapsed, approximately 31s remaining.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "74% complete, 1m 0s elapsed, approximately 20s remaining.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "86% complete, 1m 10s elapsed, approximately 10s remaining.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "99% complete, 1m 20s elapsed, approximately 0s remaining.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "100% complete, 1m 20s elapsed, approximately 0s remaining.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "-c:48: RuntimeWarning: divide by zero encountered in double_scalars\n",
        "-c:68: RuntimeWarning: divide by zero encountered in double_scalars\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We will now save all the important variables : neuron voltages, neuron spikes, and weights to a file called simulation.hdf5\n",
      "while saving the data, we will generate downsampled arrays, so when we plot we don't use that much RAM.\n",
      "if you are on ubuntu you can use:\n",
      "\n",
      "    hdfview simulation.hdf5\n",
      "to explore the dataset.\n",
      "we haven't implemented a method for downsampling sparse arrays yet, so spiketime isn't save , but it shouldn't be to hard to do that"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from brianPlotter import *\n",
      "\n",
      "bp = brianPlotter('simulation.hdf5')\n",
      "\n",
      "voltage = np.transpose(Mv[:])\n",
      "bp.saveData('voltage',voltage)\n",
      "\n",
      "del bp #you have to delete the object so the file is closed"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "If you want to see the analysis of this simulation click [here](analysis.ipynb).\n",
      "\n",
      "Remember to shutdown this notebook to release memory"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}
